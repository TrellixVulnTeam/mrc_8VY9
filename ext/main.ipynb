{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8de487-aada-4173-b2fb-78eb7db33284",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuReader-Checklist-BASELINE-main  DuReader-Checklist-BASELINE-main.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8baa58-1c2b-404d-8d6c-be352d7c735b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  DuReader-Checklist-BASELINE-main.zip\n",
      "0ac61a3b5e55923ecd0f2c5f57a161b11b177aa7\n",
      "   creating: DuReader-Checklist-BASELINE-main/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/.gitignore  \n",
      "   creating: DuReader-Checklist-BASELINE-main/.idea/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/.gitignore  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/DuReader-Checklist-BASELINE.iml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/deployment.xml  \n",
      "   creating: DuReader-Checklist-BASELINE-main/.idea/inspectionProfiles/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/inspectionProfiles/Project_Default.xml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/inspectionProfiles/profiles_settings.xml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/misc.xml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/modules.xml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/.idea/vcs.xml  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/README.md  \n",
      "   creating: DuReader-Checklist-BASELINE-main/data/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/data/License.docx  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/data/demo.json  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/data/dev.json  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/data/test1.json  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/data/train.json  \n",
      "   creating: DuReader-Checklist-BASELINE-main/dataset/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/dataset/dataset.py  \n",
      "   creating: DuReader-Checklist-BASELINE-main/metric/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/metric/metric.py  \n",
      "   creating: DuReader-Checklist-BASELINE-main/models/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/models/model.py  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/predict.py  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/run.py  \n",
      "   creating: DuReader-Checklist-BASELINE-main/utils/\n",
      "  inflating: DuReader-Checklist-BASELINE-main/utils/adversarial.py  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/utils/finetuning_argparse.py  \n",
      "  inflating: DuReader-Checklist-BASELINE-main/utils/utils.py  \n"
     ]
    }
   ],
   "source": [
    "!unzip DuReader-Checklist-BASELINE-main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8713b93-5fb7-4808-9693-be1b2b539a73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/dureaderChickList/DuReader-Checklist-BASELINE-main\n"
     ]
    }
   ],
   "source": [
    "cd DuReader-Checklist-BASELINE-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bcbe992-62bb-4147-a4ce-7c699b3b0b91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  \u001B[0m\u001B[01;34mdataset\u001B[0m/  main.ipynb  \u001B[01;34mmodels\u001B[0m/     run.py\n",
      "\u001B[01;34mdata\u001B[0m/      \u001B[01;34mluhua\u001B[0m/    \u001B[01;34mmetric\u001B[0m/     predict.py  \u001B[01;34mutils\u001B[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ecfa80-42cb-4829-af8c-63511e59e92e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting torch==1.7\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
      "\u001B[K     |████████████████████████████████| 776.7 MB 4.0 kB/s  eta 0:00:01     |▉                               | 18.9 MB 1.7 MB/s eta 0:07:33     |█                               | 23.7 MB 1.7 MB/s eta 0:07:30█▌                              | 36.3 MB 25.4 MB/s eta 0:00:30     |█▊                              | 41.1 MB 25.4 MB/s eta 0:00:29     |█▉                              | 43.4 MB 25.4 MB/s eta 0:00:29     |██                              | 47.5 MB 25.4 MB/s eta 0:00:29     |██                              | 49.5 MB 25.4 MB/s eta 0:00:29     |██▊                             | 66.7 MB 25.4 MB/s eta 0:00:28     |██▉                             | 68.7 MB 25.4 MB/s eta 0:00:28     |███                             | 70.7 MB 25.4 MB/s eta 0:00:28     |███▏                            | 77.1 MB 49.6 MB/s eta 0:00:15     |████                            | 94.5 MB 49.6 MB/s eta 0:00:14     |████▎                           | 102.8 MB 49.6 MB/s eta 0:00:14     |████▎                           | 104.8 MB 49.6 MB/s eta 0:00:14     |████▍                           | 107.1 MB 49.6 MB/s eta 0:00:14     |████▌                           | 109.2 MB 49.6 MB/s eta 0:00:14     |█████                           | 122.0 MB 55.5 MB/s eta 0:00:12     |█████▋                          | 137.5 MB 55.5 MB/s eta 0:00:12MB 45.9 MB/s eta 0:00:14     |███████▉                        | 189.1 MB 45.9 MB/s eta 0:00:13     |████████                        | 195.9 MB 45.9 MB/s eta 0:00:13     |████████▋                       | 209.0 MB 51.2 MB/s eta 0:00:12     |█████████▎                      | 225.9 MB 51.2 MB/s eta 0:00:11     |█████████▋                      | 232.5 MB 51.2 MB/s eta 0:00:11     |██████████▍                     | 252.2 MB 40.2 MB/s eta 0:00:14     |███████████▋                    | 282.9 MB 40.2 MB/s eta 0:00:13     |█████████████                   | 313.3 MB 53.6 MB/s eta 0:00:09     |█████████████▎                  | 322.2 MB 53.6 MB/s eta 0:00:09�██████████                 | 362.3 MB 40.3 MB/s eta 0:00:11     |███████████████                 | 364.9 MB 40.3 MB/s eta 0:00:11     |███████████████▊                | 382.7 MB 33.3 MB/s eta 0:00:12/s eta 0:00:12     |█████████████████               | 413.0 MB 51.0 MB/s eta 0:00:08��█████████████▋              | 428.3 MB 51.0 MB/s eta 0:00:07     |██████████████████▏             | 441.8 MB 35.8 MB/s eta 0:00:10     |██████████████████▎             | 443.8 MB 35.8 MB/s eta 0:00:10     |██████████████████▋             | 450.7 MB 35.8 MB/s eta 0:00:10     |██████████████████▊             | 455.4 MB 35.8 MB/s eta 0:00:09     |██████████████████▉             | 457.5 MB 35.8 MB/s eta 0:00:09     |███████████████████             | 459.9 MB 35.8 MB/s eta 0:00:09     |███████████████████▏            | 464.1 MB 35.8 MB/s eta 0:00:09     |███████████████████▍            | 471.0 MB 35.8 MB/s eta 0:00:09     |███████████████████▉            | 481.9 MB 35.8 MB/s eta 0:00:09     |████████████████████▍           | 494.8 MB 34.8 MB/s eta 0:00:09     |██████████████████████▍         | 543.4 MB 38.3 MB/s eta 0:00:07████████████▋         | 547.7 MB 38.3 MB/s eta 0:00:06        | 552.4 MB 38.3 MB/s eta 0:00:06     |████████████████████████▌       | 595.8 MB 42.8 MB/s eta 0:00:05     |████████████████████████▊       | 600.2 MB 42.8 MB/s eta 0:00:05     |█████████████████████████▎      | 613.7 MB 32.0 MB/s eta 0:00:06     |█████████████████████████▋      | 622.5 MB 32.0 MB/s eta 0:00:05     |██████████████████████████▋     | 647.1 MB 32.0 MB/s eta 0:00:05�███████████████████████▏   | 682.5 MB 46.9 MB/s eta 0:00:03     |█████████████████████████████▎  | 709.6 MB 34.9 MB/s eta 0:00:02     |█████████████████████████████▎  | 711.7 MB 34.9 MB/s eta 0:00:02     |██████████████████████████████▏ | 731.6 MB 34.9 MB/s eta 0:00:02�█▎ | 736.0 MB 71.4 MB/s eta 0:00:01     |██████████████████████████████▉ | 749.5 MB 71.4 MB/s eta 0:00:01     |███████████████████████████████▉| 772.0 MB 71.4 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7) (1.21.2)\n",
      "Collecting future\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829 kB)\n",
      "\u001B[K     |████████████████████████████████| 829 kB 21.8 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7) (3.10.0.2)\n",
      "Collecting dataclasses\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=8e44b2307d6019ccf62148a92cde691a1754b248b35a4a88ff9b92b7b4db4247\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/6f/cd/f72c82ed44590b04c6deb82b177f0d260aec8621f6568e0368\n",
      "Successfully built future\n",
      "Installing collected packages: future, dataclasses, torch\n",
      "\u001B[33m  WARNING: The scripts futurize and pasteurize are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n",
      "\u001B[33m  WARNING: The scripts convert-caffe2-to-onnx and convert-onnx-to-caffe2 are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n",
      "Successfully installed dataclasses-0.6 future-0.18.2 torch-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe9f3ae-65c6-4de8-9fc2-5746fc09422c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting transformers==4.5.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.1 MB 1.4 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (1.21.2)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 28.3 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (4.8.2)\n",
      "Collecting sacremoses\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/78/fef8d089db5b97546fd6d1ff2e813b8544e85670bf3a8c378c9d0250b98d/sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001B[K     |████████████████████████████████| 880 kB 78.6 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.10.0.2)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.6.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (2021.10.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=2276440b6c78361a9816c87ab1c0905c14710c093c9e100f424626c73de7a975\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/4c/43/31f85061fd938f9b9798d21dc08c7b7ba7e08ea9ef7a87b1bf\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "\u001B[33m  WARNING: The script sacremoses is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n",
      "\u001B[33m  WARNING: The script transformers-cli is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n",
      "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3239ae3-32e8-4b2e-beb1-912f9ca92d3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting rouge\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.14.0)\n",
      "Installing collected packages: rouge\n",
      "\u001B[33m  WARNING: The script rouge is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001B[0m\n",
      "Successfully installed rouge-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12966560-eea2-4aba-a9c1-e1c6663f0148",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/, https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting sklearn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/05/e561bc99a615b5c099c7a9355409e5e57c525a108f1c2e156abb005b90a6/scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 24.8 MB 43.7 MB/s eta 0:00:01   |████▊                           | 3.7 MB 1.7 MB/s eta 0:00:13     |██████████████████▋             | 14.4 MB 1.1 MB/s eta 0:00:10��██▍           | 15.8 MB 984 kB/s eta 0:00:10████████▏   | 21.9 MB 812 kB/s eta 0:00:04     |██████████████████████████████▉ | 23.9 MB 812 kB/s eta 0:00:02\n",
      "\u001B[?25hRequirement already satisfied, skipping upgrade: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/61/cf/6e354304bcb9c6413c4e02a747b600061c21d38ba51e7e544ac7bc66aecc/threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.15.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=e0c670e883a4a6c8aead09a7f3213de0b78f3490689ac6fd0a0a34d3e4ec69e4\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/ab/fb/a008fc45aa0b0e83bafb083e5e010f94cd11d988befec978af\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9a3fec-098f-4eb9-a8b7-95e806ae6a2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (3627320010.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/tmp/ipykernel_177/3627320010.py\"\u001B[0;36m, line \u001B[0;32m2\u001B[0m\n\u001B[0;31m    --max_len=256\u001B[0m\n\u001B[0m                 ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    " run.py\n",
    "--max_len=256\n",
    "--model_name_or_path=\"./luhua\"\n",
    "--per_gpu_train_batch_size=7\n",
    "--per_gpu_eval_batch_size=40\n",
    "--learning_rate=1e-5\n",
    "--linear_learning_rate=1e-4\n",
    "--num_train_epochs=100\n",
    "--output_dir=\"./output\"\n",
    "--weight_decay=0.01\n",
    "--early_stop=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8671064-23ce-4488-a382-c4adc5369900",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"adam_epsilon\": 1e-08, \n",
      "    \"cls_threshold\": 0.5, \n",
      "    \"do_distri_train\": false, \n",
      "    \"early_stop\": 2, \n",
      "    \"learning_rate\": 1e-05, \n",
      "    \"linear_learning_rate\": 0.0001, \n",
      "    \"max_answer_length\": 150, \n",
      "    \"max_len\": 512, \n",
      "    \"model_name_or_path\": \"./luhua\", \n",
      "    \"n_best_size\": 5, \n",
      "    \"num_train_epochs\": 3.0, \n",
      "    \"output_dir\": \"./output3epoch\", \n",
      "    \"per_gpu_eval_batch_size\": 40, \n",
      "    \"per_gpu_train_batch_size\": 7, \n",
      "    \"seed\": 66, \n",
      "    \"stride\": 100, \n",
      "    \"weight_decay\": 0.01\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/15/2022 17:43:20 - INFO - root -   The nums of the train_dataset examples is 835\n",
      "06/15/2022 17:43:20 - INFO - root -   The nums of the train_dataset features is 975\n",
      "06/15/2022 17:43:20 - INFO - root -   The nums of the eval_dataset examples is 83\n",
      "06/15/2022 17:43:20 - INFO - root -   The nums of the eval_dataset features is 88\n",
      "06/15/2022 17:43:37 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[Training] 139/140 [============================>.] - ETA: 1s  batch_mrc_loss: 1.9744 - batch_cls_loss: 0.5478  \t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[Training] 140/140 [==============================] 1.3s/step  batch_mrc_loss: 1.9731 - batch_cls_loss: 0.5449 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/15/2022 17:46:43 - INFO - root -   ***** Running Evalation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[Evaluating] 2/3 [===================>..........] - ETA: 2s\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "[Evaluating] 3/3 [==============================] 1.6s/step"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/run.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 277\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/run.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[0;31m# 每轮epoch在验证集上计算分数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 258\u001B[0;31m         \u001B[0meval_f1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_EM\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_iter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"eval\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    259\u001B[0m         logger.info(\n\u001B[1;32m    260\u001B[0m             \u001B[0;34m\"The F1-score is {}, The EM-score is {}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meval_f1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_EM\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/run.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(args, eval_iter, model, prefix)\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0;31m# print(type(df[\"answers\"]),type(  df[\"answers_pre\"]))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m         \u001B[0mEM\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"answers\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"answers_pre\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m         \u001B[0;31m# df_f1 = df[df[\"is_impossible\"] == False].copy()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m         \u001B[0mdf_f1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36maccuracy_score\u001B[0;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;31m# Compute accuracy for each possible representation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"multilabel\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     93\u001B[0m         raise ValueError(\n\u001B[1;32m     94\u001B[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001B[0;32m---> 95\u001B[0;31m                 \u001B[0mtype_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype_pred\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m             )\n\u001B[1;32m     97\u001B[0m         )\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of unknown and multiclass targets"
     ]
    }
   ],
   "source": [
    "%run run.py --max_len=512 --model_name_or_path=\"./luhua\" --per_gpu_train_batch_size=7 --per_gpu_eval_batch_size=40 --learning_rate=1e-5 --linear_learning_rate=1e-4 --num_train_epochs=3 --output_dir=\"./output3epoch\" --weight_decay=0.01 --early_stop=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cb65c-611b-488c-bd49-1ffd973caf1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run run.py --max_len=256 --model_name_or_path=\"./luhua\" --per_gpu_train_batch_size=7 --per_gpu_eval_batch_size=40 --learning_rate=1e-5 --linear_learning_rate=1e-4 --num_train_epochs=3 --output_dir=\"./output3epoch\" --weight_decay=0.01 --early_stop=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eede4b30-04c7-4add-8d6f-3ed150a0426d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 23:54:33.966124: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-16 23:54:33.966235: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-16 23:54:33.966245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"adam_epsilon\": 1e-08, \n",
      "    \"cls_threshold\": 0.5, \n",
      "    \"do_distri_train\": false, \n",
      "    \"early_stop\": 8, \n",
      "    \"fine_tunning_model\": \"./output5epoch/best_model.pkl\", \n",
      "    \"learning_rate\": 1e-05, \n",
      "    \"linear_learning_rate\": 0.001, \n",
      "    \"max_answer_length\": 150, \n",
      "    \"max_len\": 400, \n",
      "    \"model_name_or_path\": \"./luhua\", \n",
      "    \"n_best_size\": 5, \n",
      "    \"num_train_epochs\": 50.0, \n",
      "    \"output_dir\": \"./output\", \n",
      "    \"per_gpu_eval_batch_size\": 120, \n",
      "    \"per_gpu_train_batch_size\": 8, \n",
      "    \"seed\": 66, \n",
      "    \"stride\": 100, \n",
      "    \"weight_decay\": 0.01\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/16/2022 23:54:58 - INFO - root -   The nums of the test_dataset examples is 50000\n",
      "06/16/2022 23:54:58 - INFO - root -   The nums of the test_dataset features is 53202\n",
      "06/16/2022 23:55:17 - INFO - root -   ***** Running Evalation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[Evaluating] 443/444 [============================>.] - ETA: 2ss01\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "[Evaluating] 444/444 [==============================] 2.9s/step"
     ]
    }
   ],
   "source": [
    "%run predict.py --max_len=400 --model_name_or_path=\"./luhua\" --per_gpu_eval_batch_size=120 --output_dir=\"./output\" --fine_tunning_model=\"./output5epoch/best_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a6705f-a263-4c71-8f28-7c988e7d083c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"adam_epsilon\": 1e-08, \n",
      "    \"cls_threshold\": 0.5, \n",
      "    \"do_distri_train\": false, \n",
      "    \"early_stop\": 8, \n",
      "    \"fine_tunning_model\": \"./output5epoch/best_model.pkl\", \n",
      "    \"learning_rate\": 1e-05, \n",
      "    \"linear_learning_rate\": 0.001, \n",
      "    \"max_answer_length\": 150, \n",
      "    \"max_len\": 400, \n",
      "    \"model_name_or_path\": \"./luhua\", \n",
      "    \"n_best_size\": 5, \n",
      "    \"num_train_epochs\": 50.0, \n",
      "    \"output_dir\": \"./output\", \n",
      "    \"per_gpu_eval_batch_size\": 120, \n",
      "    \"per_gpu_train_batch_size\": 8, \n",
      "    \"seed\": 66, \n",
      "    \"stride\": 100, \n",
      "    \"weight_decay\": 0.01\n",
      "}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either input_ids or inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/main.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/main.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfine_tunning_model\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m     \u001B[0;31m# predict test\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;31m# model.eval()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dureaderChickList/DuReader-Checklist-BASELINE-main/models/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, token_type_ids, attention_mask)\u001B[0m\n\u001B[1;32m     17\u001B[0m         output = self.bert(input_ids,\n\u001B[1;32m     18\u001B[0m                            \u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m                            attention_mask=attention_mask)\n\u001B[0m\u001B[1;32m     20\u001B[0m         \u001B[0msequence_output\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpooled_output\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0mlogits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msequence_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    725\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 727\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    728\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    729\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    928\u001B[0m             \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseq_length\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m         \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0minput_ids\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0minputs_embeds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: You have to specify either input_ids or inputs_embeds"
     ]
    }
   ],
   "source": [
    "%run main.py --max_len=400 --model_name_or_path=\"./luhua\" --per_gpu_eval_batch_size=120 --output_dir=\"./output\" --fine_tunning_model=\"./output5epoch/best_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aef93-3db8-4a61-8b45-e8a86f9dc109",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}